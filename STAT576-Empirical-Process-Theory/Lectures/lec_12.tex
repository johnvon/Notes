\lecture{12}{20 Sep.\ 9:00}{Chaining Method and Dudley's Entropy Bound}
\subsection{Dudley's Entropy Bound}
To overcome the limitation of the \hyperref[lma:single-scale-bound]{single scale bound}, we can repeatedly taking \hyperref[def:eps-net]{\(\epsilon\)-net}, which is considered as a \emph{multi-scale bound}. The theorem requires one technical assumption of the stochastic process.

\begin{definition}[Separable]\label{def:separable}
	We say that \(\{X_t\}_{t\in T}\) is a \emph{separable} process if there exists a countable \(T_0 \subseteq T\) such that (outside a null set) for all \(t\in T\), there exists \(\{t_n \in T_0\}_{n}\) such that \(d(t_n, t) \to 0\) satisfying \(\lim_{n \to \infty} X_{t_n} = X_t\).
\end{definition}

It's clear that \(\sup _{t\in T_0} X_t = \sup _{t\in T} X_t\). Moreover, this notion is consistent with the separability of a topological space\footnote{A topological space is \emph{separable} if it contains a countable dense subset.} we saw in real analysis.

\begin{eg}[Separable metric space]
	If \((T, d)\) is separable (as a topological space), \(\{ X_t \} \) has countable sample path almost surely, then \(\{ X_t \} \) is \hyperref[def:separable]{separable}.
\end{eg}

Now, we can state the bound we want.

\begin{theorem}[Dudley's entropy bound]\label{thm:Dudley-entropy-bound}
	Let \(\{ X_t \} _{t\in T}\) be a centered and \hyperref[def:separable]{separable} \hyperref[def:sub-Gaussian-process]{sub-Gaussian process} on \((T, d)\) w.r.t.\ \(d\). Then
	\[
		\mathbb{E}_{}\left[\sup _{t\in T} X_t \right] \leq 6 \sum_{k\in \mathbb{Z} } 2^{-k} \sqrt{\log N(T, d, 2^{-k})} .
	\]
\end{theorem}
\begin{proof}
	Consider the case that \(\vert T \vert < \infty \) and \(\vert T \vert = \infty \).

	\begin{claim}
		The result holds for \(\vert T \vert < \infty \).
	\end{claim}
	\begin{explanation}
		Let \(K_0\) be the largest integer such that \(2^{-K_0} \geq \mathop{\mathrm{Diam}}(T) \), and let \(K_1\) be the smallest integer such that \(0 < 2^{-K_1} < \min _{s \neq t\in T} d(s, t)\). Then we let \(N_k\) be a \hyperref[def:eps-net]{\(2^{-k}\)-net} of \(T\) such that
		\begin{itemize}
			\item \(k = K_0\): \(N_{K_0} = \{ t_0 \} \) is a \hyperref[def:eps-net]{\(2^{-K_0}\)-net} of \(T\) for a fixed \(t_0\in T\).
			\item \(k = K_1\): \(N_{K_1} = T\) is a \hyperref[def:eps-net]{\(2^{-K_1}\)-net} of \(T\).
		\end{itemize}
		Write \(\pi _k(t)\) for the closest element in \(N_k\) to \(t\), in particular, \(d(t, \pi _k(t)) \leq 2^{-k}\). By writing
		\[
			X_t - X_{t_0}
			= X_{\pi _{K_1} (t)} - X_{\pi _{K_0} (t)}
			= X_{\pi _{K_1}(t)} - X_{\pi _{K_1 - 1} (t)} + X_{\pi _{K_1 - 1} (t)} - \dots + X_{\pi _{K_0 + 1} (t)} - X_{\pi _{K_0} (t)},
		\]
		hence we have
		\[
			\begin{split}
				\mathbb{E}_{}\left[\sup _{t\in T} X_t \right]
				= \mathbb{E}_{}&\left[\sup _{t\in T} X_t - X_{t_0} \right]\\
				&= \mathbb{E}_{}\left[\sup _{t\in T} \sum_{k=K_0 + 1}^{K_1} \left( X_{\pi _k (t)} - X_{\pi _{k-1}(t)} \right) \right]
				\leq \sum_{k=K_0 + 1}^{K_1} \mathbb{E}_{}\left[\sup _{t\in T} \left( X_{\pi _k(t)} - X_{\pi _{k-1} (t)} \right) \right].
			\end{split}
		\]
		Since the cardinality of \(\{ X_{\pi _k(t)} - X_{\pi _{k-1} (t)} \}_{t\in T}\) is \(\vert N_k \vert \vert N_{k-1} \vert \leq \vert N_k \vert ^2\), and
		\[
			X_{\pi _k(t)} - X_{\pi _{k-1}(t)} \sim \Subg(d^2(\pi _k(t), \pi _{k-1}(t)))
		\]
		with \(d(\pi _k(t), \pi _{k-1}(t)) \leq d(\pi _k(t), t) + d(t, \pi _{k-1}(t)) \leq 2^{-k} + 2^{-k+1} \leq 3\cdot 2^{-k}\), from \autoref{lma:sub-Gaussian-finite-maximum},
		\[
			\mathbb{E}_{}\left[\sup _{t\in T} \left( X_{\pi _k(t)} - X_{\pi _{k-1}(t)} \right) \right]
			\leq 3 \times 2^{-k} \sqrt{2 \log \vert N_k \vert ^2}
			= 6 \times 2^{-k} \sqrt{\log \vert N_k \vert }
		\]
		for each \(k\). Summing over \(k\) yields the result.
	\end{explanation}

	\begin{claim}
		The result holds for \(\vert T \vert = \infty \).
	\end{claim}
	\begin{explanation}
		From \hyperref[def:separable]{separability}, there exists a countable \(T_0\) such that \(\mathbb{E}_{}\left[\sup _{t\in T_0} X_t \right] = \mathbb{E}_{}\left[\sup _{t\in T} X_t \right] \). Let \(T_k\) be a countable approximation of \(T_0\), then \(\sup _{t\in T_k} X_t \to \sup _{t\in T_0} X_t \) as \(k \to \infty\), so
		\[
			\mathbb{E}_{}\left[\sup _{t\in T_k} X_t \right] \to  \mathbb{E}_{}\left[\sup _{t\in T_0} X_t \right] = \mathbb{E}_{}\left[\sup _{t\in T} X_t \right] \text{ as }k \to \infty
		\]
		from monotone convergence theorem. Hence, it suffices to bound \(\mathbb{E}_{}\left[\sup _{t\in T_k} X_t \right] \) instead of \(\mathbb{E}_{}\left[\sup _{t\in T} X_t \right] \) for each \(k\). As \(\vert T_k \vert < \infty \) and \(N(T_k, d, 2^{-k}) \leq N(T_0, d, 2^{-k})\) for all \(k\),
		\[
			6 \sum_{k\in \mathbb{Z} } 2^{-k} \sqrt{\log N(T_k, d, 2^{-k})} \leq 6 \sum_{k\in \mathbb{Z} } 2^{-k} \sqrt{\log N(T_0, d, 2^{-k})} .
		\]
	\end{explanation}
\end{proof}

\begin{note}[Chaining method]\label{note:chaining}
	This method is called \emph{chaining} since we're constructing a chain of \(X_{\pi _{k}(t)}\), with smaller and smaller distances.
	\begin{figure}[H]
		\centering
		\incfig{chaining}
	\end{figure}
\end{note}

An alternative integral form of \hyperref[thm:Dudley-entropy-bound]{Dudley's entropy bound} is given by the following.

\begin{corollary}[Dudley integral entropy bound]\label{col:Dudley-integral-entropy-bound}
	Let \(\{ X_t \} _{t\in T}\) be a centered and \hyperref[def:separable]{separable} \hyperref[def:sub-Gaussian-process]{sub-Gaussian process} on \((T, d)\) w.r.t.\ \(d\). Then
	\[
		\mathbb{E}_{}\left[\sup _{t\in T} X_t \right] \leq 12 \int_{0}^{\mathop{\mathrm{Diam}}(T) }\sqrt{\log N(T, d, \epsilon )} \,\mathrm{d}\epsilon.
	\]
\end{corollary}
\begin{proof}
	Observe that
	\begin{align*}
		\sum_{k\in \mathbb{Z} } 2^{-k} \sqrt{\log N(T, d, 2^{-k})}
		 & = 2 \sum_{k\in \mathbb{Z} } \int_{2^{-k-1}}^{2^{-k}} \sqrt{\log N(T, d, 2^{-k})}  \,\mathrm{d} \epsilon                                                                        \\
		 & \leq 2 \sum_{k\in \mathbb{Z} } \int_{2^{-k-1}}^{2^{-k}} \sqrt{\log N(T, d, \epsilon )} \,\mathrm{d} \epsilon \tag*{\(N(T, d, \epsilon ) \nearrow \) as \(\epsilon \searrow \)} \\
		 & = 2 \int_{0}^{\infty} \sqrt{\log N(T, d, \epsilon )} \,\mathrm{d}\epsilon                                                                                                      \\
		 & = 2 \int_{0}^{\mathop{\mathrm{Diam}}(T) } \sqrt{\log N(T, d, \epsilon )} \,\mathrm{d}\epsilon. \tag*{\(\epsilon > \mathop{\mathrm{Diam}}(T) \), \(N(T, d, \epsilon ) = 1\)}
	\end{align*}
\end{proof}

Now, we note that we have finally reached the optimal bound for \(S_1\), solving the problems we saw in the \hyperref[eg:non-optimal-EP-supremum-S1]{previous example}.

\begin{eg}[Supremum of empirical process for \(S_1\)]\label{eg:optimal-EP-supremum-S1}
	Consider the \hyperref[def:separable]{separable} \hyperref[def:sub-Gaussian-process]{sub-Gaussian process} \(X_f = \sqrt{n} (\mathbb{P} _n f - \mathbb{P} f)\) for \(\mathscr{F} = S_1\). In particular, \(f, g\in \mathscr{F} \) are \(1\)-Lipschitz on \([0, 1]\) satisfying \(\vert f \vert , \vert g \vert \leq 1\) and \(X_f - X_g\in \Subg(2^2 \lVert f - g \rVert ^2_\infty )\). Since \(\mathop{\mathrm{Diam}}(\mathscr{F} ) = 2 \) and for all \(\epsilon < 1 / 2\),
	\[
		N(S_1, \lVert \cdot \rVert _\infty , \epsilon ) = \exp (c / \epsilon )
	\]
	from \autoref{thm:metric-entropy}. Then by the \hyperref[col:Dudley-integral-entropy-bound]{Dudley's integral entropy bound},
	\[
		\mathbb{E}_{}\left[\sup _{f\in \mathscr{F} } X_f \right]
		\leq 12\int_{0}^{2} \sqrt{\log N(S_1, \lVert \cdot \rVert _\infty , \epsilon )} \,\mathrm{d}\epsilon
		= 12 \int_{0}^{2} \sqrt{\frac{c}{\epsilon }} \,\mathrm{d}\epsilon
		= 24 \sqrt{2c}
		< O_n(1).
	\]
	Dividing both sides by \(\sqrt{n} \), we achieve the optimal rate \(\mathbb{E}_{}\left[\sup _{f\in \mathscr{F} } (\mathbb{P} _n f - \mathbb{P} f) \right] = O(1 / \sqrt{n} )\).
\end{eg}

\begin{remark}
	The \hyperref[col:Dudley-integral-entropy-bound]{Dudley's integral entropy bound} for \(\mathcal{S} _\alpha \) is also finite; while for function classes with \hyperref[def:covering-number]{covering number} as \(\exp (c / \epsilon ^2)\) is divergent.
\end{remark}