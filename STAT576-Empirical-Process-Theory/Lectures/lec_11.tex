\lecture{11}{18 Sep.\ 9:00}{Gaussian and Sub-Gaussian Process}
\begin{prev}
	Given a stochastic process \(\{ X_t \} _{t\in T}\) with \((T, d)\), we want to bound \(\mathbb{E}_{}\left[\sup _{t\in T} X_t \right] \).
\end{prev}

Recall our \hyperref[int:informal-principle]{informal principle}, i.e., if \(\{ X_t \} _{t\in T}\) is sufficiently continuous w.r.t.\ \(d\), then \(\mathbb{E}_{}\left[\sup _{t\in T} X_t\right] \) is governed by metric properties (e.g., \hyperref[def:metric-entropy]{metric entropy}) of \(T\).

What we mean by ``sufficiently continuous'' is the following.

\begin{definition}[Gaussian process]\label{def:Gaussian-process}
	A stochastic process \(\{ X_t \} _{t\in T}\) is a \emph{Gaussian process} if for any finite set of indices \({t_1, \dots , t_k}\), \((X_{t_1}, \dots , X_{t_k}) \sim \mathcal{N} (0, \mathbf{\Sigma} ) \).
\end{definition}

We see that
\[
	\mathbb{E}_{}\left[e^{\lambda (X_t - X_{t^{\prime} })} \right]
	= e^{\lambda ^2 / 2 \mathbb{E}_{}\left[X_t - X_{t^{\prime} } \right] }
	= \exp \left( \frac{\lambda ^2}{2} d^2(t, t^{\prime} ) \right),
\]
where \(d(t, t^{\prime} ) = \sqrt{\mathbb{E}_{}\left[ (X_t - X_{t^{\prime} })^2 \right]}\).

\begin{definition}[Sub-Gaussian process]\label{def:sub-Gaussian-process}
	A stochastic process \(\{ X_t \} _{t\in T}\) is a \emph{sub-Gaussian process} w.r.t.\ \(d\) if \(X_t - X_s \sim \Subg(d^2(t, s))\).
\end{definition}

In other words, assume \(\mathbb{E}_{}\left[X_t \right] = 0\) for all \(t\in T\), and
\[
	\mathbb{E}_{}\left[e^{\lambda (X_t - X_s)} \right]
	\leq \exp \left( \frac{\lambda ^2}{2} d^2(t, s) \right)
\]
for all \(t \neq s\in T\).

\begin{eg}[Rademacher process]\label{eg:Rademacher-process}
	Consider the \hyperref[def:Rademacher-width]{Rademacher width} (without normalization) of a set \(T \subseteq \mathbb{R} ^n\),
	\[
		R_n(T) = \mathbb{E}_{}\left[\sup _{t\in \mathbb{R} ^n} \sum_{i=1}^{n} \epsilon _i t_i \right] .
	\]
	Let \(X_t = \langle \epsilon , t \rangle \), then \(X_t - X_{t^{\prime} } = \langle \epsilon , t-t^{\prime}  \rangle \sim \Subg(\lVert t - t^{\prime}  \rVert_2^2 )\), i.e., \(X_t \sim \Subg\) w.r.t.\ \(\lVert \cdot \rVert _2\).
\end{eg}

\begin{eg}[Gaussian width]\label{eg:Gaussian-width}
	The \emph{Gaussian width} of a set \(T \subseteq \mathbb{R} ^n\) is defined as \(X_t = \langle g, t \rangle \), i.e., we replace \(\epsilon \) by \(g\). We have \(X_t \sim \Subg\) w.r.t.\ \(\lVert \cdot \rVert _2\).
\end{eg}

\begin{theorem}
	Denote \(\mathop{\mathrm{GW}}(T) \) be the \hyperref[eg:Gaussian-width]{Gaussian width} of a set \(T\), then
	\[
		R_n(T) \leq \mathop{\mathrm{GW}}(T) \leq \sqrt{n} R_n(T)
	\]
\end{theorem}

Let's look at some examples of \hyperref[def:Rademacher-width]{Rademacher width}.

\begin{eg}
	\(R(B_\infty ^n) = n\), \(R(B_2^n)= \sqrt{n} \), and \(R(B_1^n) \leq \lVert \epsilon \rVert _\infty \lVert t \rVert _1 = 1\) by Holder's inequality.
\end{eg}

\begin{eg}
	Let \(\mathscr{F} \) be a class of functions bounded by \(1\). Let \(X_f = \sqrt{n} (\mathbb{P} _n f - \mathbb{P} f)\), and consider \(\{ X_f \}_{f\in \mathscr{F} } \). Then,
	\[
		X_f - X_g
		= \sqrt{n} \frac{1}{n}\sum_{i=1}^{n} ( \underbrace{f(x_i) - g(x_i) - \mathbb{P} f - \mathbb{P} g }_{\leq 2 \lVert f-g \rVert _\infty })
		\sim \Subg\left( 4 \lVert f - g \rVert _\infty ^2 \right) ,
	\]
	hence \(\{ X_f \} _{f\in \mathscr{F} } \sim \Subg\) w.r.t.\ \(\lVert \cdot \rVert _\infty \).
\end{eg}

\begin{definition}[Diameter]\label{def:diameter}
	The \emph{diameter} of \((T, d)\) is defined as \(\mathop{\mathrm{Diam}}(T) = \sup _{t, t^{\prime} \in T} d(t, t^{\prime} )\).
\end{definition}

\begin{lemma}[Single scale bound]\label{lma:single-scale-bound}
	Let \(\{ X_t \} _{t\in T}\) be a centered \hyperref[def:sub-Gaussian-process]{sub-Gaussian process} on \((T, d)\) w.r.t.\ \(d\). Then
	\[
		\mathbb{E}_{}\left[\sup _{t\in T} X_t \right]
		\leq \inf _{\epsilon > 0} \left( \mathbb{E}_{}\left[\sup _{\substack{t, t^{\prime} \in T\colon \\ d(t, t^{\prime} ) \leq \epsilon }} X_t - X_{t^{\prime} } \right] + \mathop{\mathrm{Diam}}(T) \sqrt{2 \log N(T, d, \epsilon )} \right) .
	\]
\end{lemma}
\begin{proof}
	We first note that \(\mathbb{E}_{}\left[\sup _{t\in T} X_t \right] = \mathbb{E}_{}\left[\sup _{t\in T} X_t - X_{t_0} \right]  \) for some fixed \(t_0\in T\). Now, take an \hyperref[def:eps-net]{\(\epsilon\)-net} \(N\) with \(\pi (t) \in N\) denotes the point such that \(d(t, \pi (t)) \leq \epsilon \), then
	\[
		\mathbb{E}_{}\left[\sup _{t\in T} X_t - X_{t_0} \right]
		\leq \mathbb{E}_{}\left[\sup _{t\in T} X_t - X_{\pi (t)} \right] + \mathbb{E}_{}\left[\sup _{t\in T} X_{\pi (t)} - X_{t_0} \right]
	\]
	Observe that \(X_{\pi (t)} - X_{t_0} \sim \Subg(\mathop{\mathrm{Diam}}^2(T) )\), then the second term is a finite maximum such that
	\[
		\mathbb{E}_{}\left[\sup _{t\in T} X_{\pi (t)} - X_{t_0} \right]
		\leq \sqrt{2 \mathop{\mathrm{Diam}}\nolimits^2(T) \log N(T, d, \epsilon )}
		= \mathop{\mathrm{Diam}}(T) \sqrt{2 \log N(T, d, \epsilon )}
	\]
	from \autoref{lma:sub-Gaussian-finite-maximum}. By rewriting the first term, we have
	\[
		\mathbb{E}_{}\left[\sup _{t\in T} X_t \right]
		\leq \inf _{\epsilon > 0} \left( \mathbb{E}_{}\left[\sup _{\substack{t, t^{\prime} \in T\colon \\ d(t, t^{\prime} ) \leq \epsilon }} X_t - X_{t^{\prime} } \right] + \mathop{\mathrm{Diam}}(T) \sqrt{2 \log N(T, d, \epsilon )} \right) .
	\]
\end{proof}

\begin{eg}
	For \hyperref[eg:Rademacher-process]{Rademacher process}, we have \(\mathbb{E}_{}\left[\sup _{t, t^{\prime} \in T \colon \lVert t - t^{\prime} \rVert \leq \epsilon } \langle \vec{\epsilon} , t - t^{\prime}  \rangle  \right] \leq \lVert \vec{\epsilon} \rVert \epsilon \leq \sqrt{n} \epsilon  \).
\end{eg}

Let's see some applications of \hyperref[lma:single-scale-bound]{single scale bound}.

\begin{eg}
	Let \(T = \{ (0, 0, \dots , 0), (1, 0, \dots , 0), \dots , (1, 1, \dots , 1) \} \subseteq \mathbb{R} ^n\), then
	\[
		R_n(T) \leq \sqrt{n \log n} .
	\]
	We see that we still can't remove the \(\sqrt{\log n}\): from the \hyperref[lma:single-scale-bound]{single scale bound},
	\[
		\sqrt{n} \epsilon + \sqrt{n} \sqrt{\log N(T, \lVert \cdot \rVert _2, \epsilon )}.
	\]
	To remove \(\log n\), one need to choose \(\epsilon = O(1)\), but then \(\log N(T, \lVert \cdot \rVert _2, \epsilon )\) goes to infinity, and we fail.
\end{eg}

\begin{eg}
	Again, consider \(X_f = \sqrt{n} (\mathbb{P} _n f - \mathbb{P} f)\) on \(\mathscr{F} \) of functions bounded by \(1\). Then \(X_f \sim \Subg(2^2 \lVert f-g \rVert _\infty ^2)\). By letting \(\mathscr{F} = S_1\) (\autoref{def:Holder-smooth-function-class}),
	\[
		\mathbb{E}_{}\left[\sup X_f \right]
		\leq c \left(  \sqrt{n} \epsilon + \sqrt{1 / \epsilon } \right)
	\]
	from \hyperref[lma:single-scale-bound]{single scale bound} and \autoref{thm:metric-entropy}. By letting \(\epsilon = n^{-1 / 3}\), this bound is minimized, giving us
	\[
		\mathbb{E}_{}\left[\sup \mathbb{P} _n f - \mathbb{P} f \right] \leq \frac{c}{n^{1 / 3}}.
	\]
	However, this is not optimal.
	\begin{remark}
		The optimal bound is \(c / \sqrt{n} \).
	\end{remark}
\end{eg}