\lecture{13}{20 Oct. 12:30}{Stochastic Process and Markov Chain}
Let's first see some examples of \hyperref[def:i.i.d.]{i.i.d.} \hyperref[def:stochastic-process]{stochastic process}, where \(i\) is the time index unspecified.
\begin{eg}[Biased coin toss]
	For all \(i\), let \(X_{i}\in\{0, 1\}\) and
	\[
		\Pr(X_{i} = 1) = p.
	\]
	We denote this as \(X_i\sim \mathrm{Beronulli}(p)\).
\end{eg}

\begin{eg}[Dice toss]
	For all \(i\), let \(X_{i}\in\{1, 2, 3, 4, 5, 6\}\) and
	\[
		\Pr(X_{i} = j) = \frac{1}{6}.
	\]
	We denote this as \(X_i\sim \mathrm{Uniform}(\{1, 2, 3, 4, 5, 6\})\).
\end{eg}

\begin{eg}[Uniform distribution]
	For all \(i\), let \(X_i\sim \mathrm{Uniform}(\left[ 0, 1 \right] )\), where \(X_{i}\in\left[ 0, 1 \right] \).
\end{eg}

\begin{eg}[Exponential distirbution]
	For all \(i\), let \(X_i\sim \mathrm{exp}(\lambda)\), then
	\[
		\Pr(X_{i}>u) = e^{-\lambda u}\qquad \forall u\geq 0.
	\]
\end{eg}

\begin{eg}[Normal distribution]
	For all \(i\), let \(X_i\sim \mathcal{N}(\mu, \sigma^2)\).
\end{eg}

\begin{remark}
	Notice that our discussion will focus on \(\mathbb{E}\left[X_i \right] < +\infty \).
\end{remark}

The main reason we study \hyperref[def:i.i.d.]{i.i.d.} \hyperref[def:stochastic-process]{stochastic process} is because of the following theorem.
\begin{theorem}[Strong law of large numbers]\label{thm:SLLN}
	For an \hyperref[def:i.i.d.]{i.i.d.} sequence \(\{X_i\}\), it follows that
	\[
		\lim_{n \to \infty} \frac{1}{n}\sum\limits_{i=1}^{n} X_{i} = \mathbb{E}\left[X \right].
	\]
	This is so-called the \emph{strong law of large numbers} (SLLN).
\end{theorem}

\begin{eg}[Coin toss]
	If an unfair coin will face up with probability \(p\), then \hyperref[thm:SLLN]{strong law of large numbers} tells us that
	\[
		\frac{\# \mathrm{H} }{\# \mathrm{H} + \# \mathrm{T} } \cong p
	\]
	with many enough tosses. Mathematically, we let \(Y_{i} = \mathbbm{1}_{\{X_{i}\in B\}}\), where
	\[
		\mathbbm{1}_{\{X_{i}\in B\}}(\omega) = \begin{dcases}
			0, & \text{ if }X_{i}(\omega)\in B; \\
			1, & \text{ otherwise},
		\end{dcases}
	\]
	hence \(y_{i}\sim \mathrm{Bernoulli}(p = \Pr(X_{i}\in B))\). Then we can use the \hyperref[def:i.i.d.]{i.i.d.} sequence \(Y_i\) to describe a series of coin tosses.
\end{eg}

\subsection{Conditional Property}
\begin{prev}
	We first note that if \(\Pr(A\cap B) = \Pr(A) \Pr(B) \), then \(A\) and \(B\) are \hyperref[def:independent]{independent}.
\end{prev}

Now, if \(A\) and \(B\) are dependent, then given \(B\) is happened, we should be able to say something about the probability under the current condition. This suggests the following definition.

\begin{definition}[Conditional probability]\label{def:conditional-probability}
	Let \(\Pr(B)>0\), then the \emph{conditional probability} of event \(A\) under condition \(B\) is defined as
	\[
		\Pr(A \mid B)\coloneqq \frac{\Pr(A\cap B)}{\Pr(B)}.
	\]
\end{definition}

Similarly, we have the \hyperref[def:conditional-expectation]{conditional expectation}
\begin{definition}[Conditional expectation]\label{def:conditional-expectation}
	The \emph{conditional expectation} is defined as
	\[
		\mathbb{E}\left[X \mid X\in A \right] = \mathbb{E}\left[X \mid A \right].
	\]
\end{definition}

\begin{eg}
	We look at an example for discrete \hyperref[def:random-variable]{random variable} \(X\). Let \(X\in \Omega\), then
	\[
		\begin{split}
			\mathbb{E}\left[X \mid X\in A \right] &= \sum\limits_{\omega\in \Omega} \omega\Pr(X = \omega \mid X\in A)\\
			&=\sum\limits_{\omega\in \Omega} \omega \frac{\Pr(\left\{X = \omega\right\}\cap \left\{x\in A\right\})}{\Pr(X\in A) }\\
			&=\sum\limits_{\omega\in \Omega} \omega \frac{\Pr(X = \omega)}{\Pr(X\in A) }\\
			&=\frac{\sum\limits_{\omega\in \Omega} \omega \Pr(X = \omega)}{\Pr(X\in A)}
		\end{split}
	\]
\end{eg}

Now, consider three events \(A, B, C\), then we have
\[
	\Pr(X\in A, X\in B, X\in C) \coloneqq \Pr(X\in A\cap B\cap C).
\]
Then if \(A, B,  C\) are \hyperref[def:independent]{independent}, then we further have
\[
	\Pr(X\in A\cap B\cap C)= \Pr(X\in A)\Pr(X\in B)\Pr(X\in C)
\]
as we have seen. If they are dependent, given \(\Pr(X\in C) > 0\), then
\[
	\Pr(X\in A, X\in B, X\in C) = \Pr(X\in A, X\in B \mid X\in C) \Pr(X\in C).
\]
This suggests the notion of \hyperref[def:conditionally-independent]{conditional independence} as follows to help us further factorize the above equation.
\begin{definition}[Conditionally independent]\label{def:conditionally-independent}
	For events \(A, B, C\), if
	\[
		\Pr(X\in A, X\in B \mid X\in C) = \Pr(X\in A \mid X\in C)\Pr(X\in B \mid X\in C),
	\]
	then \(A\) and \(B\) are \emph{conditionally independent} given \(C\).
\end{definition}

\section{Markov Chain}
We now formally define \hyperref[def:Markov-chain]{Markov chain}.
\begin{definition}[Markov chain]\label{def:Markov-chain}
	A \emph{Markov chain} is a dependent \hyperref[def:stochastic-process]{stochastic process} with a specific form of \hyperref[def:conditionally-independent]{conditional independence} defined as follows. Consider a \hyperref[def:random-variable]{random variables} sequence
	\[
		X_1, X_2, X_3, \ldots
	\]
	with discrete time index \(1, 2, 3, \ldots \).\footnote{Noting that they lie on a \underline{discrete space}, like real number, labels, etc.} At time \(n>1\), we have \(X_n = a_n\) where \(a_n\) takes values in a discrete set. Then
	\[
		\begin{split}
			&\Pr(X_1 = a_1, X_2 = a_2,  \ldots X_{n-1} = a_{n-1}, X_{n+1} = a_{n+1},\ldots , X_{n+m} = a_{n+m}  \mid X_n = a_n )\\
			=&\Pr(X_1 = a_1, X_2 = a_2,  \ldots X_{n-1} = a_{n-1}\mid X_n = a_n )\\
			&\qquad\qquad\qquad\qquad\qquad\qquad\qquad\quad\cdot \Pr(X_{n+1} = a_{n+1},\ldots , X_{n+m} = a_{n+m}  \mid X_n = a_n).
		\end{split}
	\]
\end{definition}

\begin{intuition}[Conditional independence property of Markov chains]
	Knowing where we are, the progress in the future is \hyperref[def:conditionally-independent]{conditionally independent} of how we got to the present, i.e., knowing the present, the past and the future are \hyperref[def:conditionally-independent]{conditionally independent}.
\end{intuition}

\begin{note}
	\hyperref[def:Markov-chain]{Markov chains} will not be \hyperref[def:i.i.d.]{i.i.d.} sequences of \hyperref[def:random-variable]{random variables} since there will be dependence. But still, the \hyperref[thm:SLLN]{strong law of large number} will hold under conditions.
\end{note}

\subsection{Time Homogeneous Markov Chain}
We need to know two things:
\begin{itemize}
	\item initial distribution \(X_0 \sim \mu\) (or \(X_1\sim \mu\))
	\item one-step transition matrix
	      \[
		      P_{ij} \coloneqq \Pr(X_{n+1} = j \mid X_n = i)\qquad \forall i, j.
	      \]
	      \begin{note}
		      Note that
		      \begin{enumerate}
			      \item Notice that this is not a function of \(n\).
			      \item The condition here is just for an example from the lecture.\todo{Review the example in lecture}
		      \end{enumerate}
	      \end{note}

	      Then we see that the total probability of \(\Pr(X_n = i)\) is
	      \[
		      \begin{split}
			      \Pr(X_n = i) &= \sum_j \Pr(X_n = i, X_0 = j)\\
			      &= \sum_j \Pr(X_0 = j)\Pr(X_n = i  \mid  X_0 = j)\\
			      &=\sum_j \mu_{j} (P^n)_{ji}\\
			      &= (\mu^{\top} P^n)_i
		      \end{split}
	      \]
	      where the first step is from the definition of \emph{total probability}. Recall that
	      \[
		      P_{ij} = \Pr(X_{n+1} = j \mid X_n = i),
	      \]
	      hence
	      \[
		      \begin{split}
			      \sum_{j\in \Omega} P_{ij} &= \sum_{j\in \Omega} \Pr(X_{n+1} = j \mid X_n = i)\\
			      &= \Pr(X_{n+1}\in \Omega \mid X_n = i)\\
			      &= \frac{\Pr(X_{n+1}\in \Omega, X_n = i)}{\Pr(X_n = i)}
			      = \frac{\Pr(X_n = i)}{\Pr(X_n = i)}
			      = 1.
		      \end{split}
	      \]
	      We see that \(P\) is row stochastic and \(P_{i\cdot}\) is a probability distribution on \(\Omega\). So \(\rho(P) = 1\implies \exists  \pi\)(distribution) such that
	      \[
		      \pi^{\top} P = \pi^{\top}.
	      \]
	      We see that the left \hyperref[def:eigenvector]{eigenvector} is a distribution. We have \(P\) is irreducible and \(\Omega\) is finite, then
	      \[
		      \lim_{n\to \infty } \frac{1}{n}\underline{\sum\limits_{m=1}^{n}  \mathbbm{1}_{\left\{ X_m = i \right\} }} = \pi_i
	      \]
	      almost surely.
\end{itemize}

Refinement with aperiodic \(P\),
\[
	\lim_{n\to \infty }\Pr(X_n = i) = \pi_i
\]