\lecture{22}{07 Mar.\ 11:00}{Lebesgue Differentiation Theorem}
We should compare the \hyperref[thm:HL-maximal-inequality]{Hardy-Littlewood maximal inequality} to \hyperref[lma:Markov-inequality]{Markov's inequality}.
Namely, there exists \(C_{d} >0\) (can take \(3^d\)) such that for all \(f\in L^1(\mathbb{R} ^d)\), \(\alpha > 0\), we have
\[
	\begin{dcases}
		m(\left\{x\mid \operatorname{H}f(x) > \alpha\right\})                \leq \frac{C_{d} }{\alpha }\int \left\vert f \right\vert; \\
		m(\left\{x\mid \left\vert f(x) \right\vert > \alpha \right\})  \leq \frac{1}{\alpha }\int \left\vert f \right\vert.
	\end{dcases}
\]

\section{Lebesgue Differentiation Theorem}
We start with a theorem!
\begin{theorem}[Lebesgue differentiation theorem]\label{thm:Lebesgue-differentiation}
	Let \(f\in L^1\), then
	\[
		\lim_{r \to 0} \frac{1}{m(B(x, r))}\int_{B(x, r)}\left\vert f(y) - f(x) \right\vert   \,\mathrm{d}y = 0
	\]
	for \hyperref[def:mu-almost-everywhere]{a.e.} \(x\).
\end{theorem}
\begin{proof}
	The result holds for \(f\in C_c(\mathbb{R} ^d)\), namely for those continuous functions with \textbf{compact} \hyperref[def:support]{support}.
	This is because for any \(\epsilon >0\), if \(r\) is small and \(\left\vert f(y) - f(x) \right\vert < \epsilon \), then
	\[
		\frac{1}{m(B(x, r))}\int _{B(x, r)}\left\vert f(y) - f(x) \right\vert \,\mathrm{d} y < \epsilon .
	\]

	Now, let \(f\in L^1(\mathbb{R} ^d)\) and fix \(\epsilon >0\). By density, there exists \(g\in C_c(\mathbb{R} ^d)\) with \(\left\lVert f-g\right\rVert _1<\epsilon \).
	We then have
	\[
		\int_{B_r(x)}\left\vert f(y) - f(x) \right\vert \,\mathrm{d} y
		\leq \int _{B_r(x)}\left\vert f(y) - g(y) \right\vert \,\mathrm{d} y
		+\int _{B_r(x)}\left\vert g(y) - g(x) \right\vert \,\mathrm{d} y
		+\int _{B_r(x)}\left\vert g(x) - f(x) \right\vert \,\mathrm{d} y.
	\]
	\begin{note}
		We use \(B_r(x)\) above to denote \(B(x, r)\) for spacing reason only. Nothing tricky here.
	\end{note}
	Divide all of these by \(m(B(x, r))\), and take \(\limsup_{r \to \infty} \), we need to understand the error terms, namely
	\[
		\frac{1}{m(B(x, r))}\int _{B(x, r)}\left\vert f(x) - g(x) \right\vert \,\mathrm{d} y = \left\vert g(x) - f(x) \right\vert
	\]
	and
	\[
		\frac{1}{m(B(x, r))}\int _{B(x, r)}\left\vert f(y) - g(y) \right\vert \,\mathrm{d} y \leq (\operatorname{H} (f-g))(x).
	\]
	We define
	\[
		Q(x) \coloneqq \limsup_{r \to \infty} \frac{1}{m(B(x, r))}\int _{B(x, r)} \left\vert f(y) - f(x) \right\vert \,\mathrm{d} y.
	\]
	We want to show \(m(\{x\in X\mid Q(x) > 0\}) = 0\). Let \(E_\alpha = \{x\in X\mid Q(x) > \alpha \}\). It is enough to show \(m(E_\alpha ) = 0\)
	for all \(\alpha >0\) because \(\{x\in X\mid Q(x)> 0\}= \bigcup_n E_{\frac{1}{n}}\). We know by the above that
	\[
		Q(x) \leq (\operatorname{H} (f-g))(x) + 0 + \left\vert g(x) - f(x) \right\vert.
	\]
	Therefore,
	\[
		E_\alpha \subset \{x\in X\mid (\operatorname{H} (f-g))(x) > \alpha /2\}\cup \{x\in X\mid \left\vert g(x) - f(x) \right\vert >\alpha /2\}.
	\]
	By the \hyperref[thm:HL-maximal-inequality]{Hardy-Littlewood maximal inequality} and \hyperref[lma:Markov-inequality]{Markov's inequality}, we have
	\[
		\begin{dcases}
			m(\left\{x\mid (\operatorname{H}(f-g))(x) > \alpha / 2\right\})                \leq \frac{2C_{d} }{\alpha }\int \left\vert f - g \right\vert; \\
			m(\left\{x\mid \left\vert g(x) - f(x) \right\vert > \alpha / 2\right\})  \leq \frac{2}{\alpha }\int \left\vert f - g \right\vert.
		\end{dcases}
	\]
	Thus,
	\[
		0\leq m(E_\alpha )\leq \frac{2C_d}{\alpha }\left\lVert f-g\right\rVert _1 + \frac{2}{\alpha }\left\lVert f-g\right\rVert _1 \leq \frac{2(C_{d} +1)}{\alpha }\epsilon.
	\]
	Taking \(\epsilon \to 0\), \(m(E_\alpha )\) does not depend on \(\epsilon \) and \(g\), hence \(m(E_\alpha) = 0\).
\end{proof}
\begin{corollary}\label{col:lec-22-1}
	\autoref{thm:Lebesgue-differentiation} also holds for \(f\in L^1_{\text{loc}}(\mathbb{R} ^d)\).
\end{corollary}
\begin{proof}
	Using the fact that \(m^d\) is \hyperref[def:finite-measure]{\(\sigma \)-finite}, and apply \autoref{thm:Lebesgue-differentiation}.
	Specifically, partition \(\mathbb{R} ^d\) into countably many compact sets \(K_{i} \) and apply \autoref{thm:Lebesgue-differentiation}
	to \(f\mathbbm{1}_{K_{i} } \) for all \(i\).
\end{proof}

\begin{corollary}\label{col:lec-22-2}
	For \(f\in L^1_{\text{loc} }\), we have
	\[
		\lim_{r \to 0} \frac{1}{m(B(x, r))}\int_{B(x, r)}^{} f(y) \,\mathrm{d}y = f(x)
	\]
	for \hyperref[def:mu-almost-everywhere]{a.e.} \(x\).
\end{corollary}
\begin{proof}
	Use that
	\[
		f(x) = \frac{1}{m(B(x, r))}\int _{B(x, r)} f(x)\,\mathrm{d} y
	\]
	and the triangle inequality.\todo{DIY}
\end{proof}

\begin{definition}[Lebesgue point]\label{def:Lebesgue-point}
	Let \(f\in L^1_{\text{loc}}(\mathbb{R} ^d)\), the point \(x\in \mathbb{R} ^d\) is called a \emph{Lebesgue point of \(f\)} if
	\[
		\lim_{r \to 0} \frac{1}{m(B(x, r))}\int _{B(x, r)}\left\vert f(y) - f(x) \right\vert \,\mathrm{d} y = 0.
	\]
\end{definition}
\begin{remark}
	\autoref{col:lec-22-1} tells us that almost all points in \(\mathbb{R} ^d\) in \(\mathbb{R} ^d\) are \hyperref[def:Lebesgue-point]{Lebesgue points}  for \(f\).
\end{remark}

\begin{definition}[Shrink nicely]\label{def:shrink-nicely}
	We say that \(\left\{E_{r} \right\}_{r>0}\) \emph{shrinks nicely} to \(x\) as \(r\to 0\) if \(E_{r} \subset B(x, r)\) and
	\[
		\underset{c>0}{\exists } \ c\cdot m(B(x, r)) \leq m(E_{r} ).
	\]
\end{definition}
\begin{note}
	Here, \(c\) is independent of \(r\).
\end{note}

\begin{corollary}
	Suppose \(E_r\) \hyperref[def:shrink-nicely]{shrink nicely} to \(0\), and \(f\in L^1_{\text{loc}}(\mathbb{R} ^d)\), and \(x\) is a \hyperref[def:Lebesgue-point]{Lebesgue point}.
	Then
	\[
		\lim_{r \to 0} \frac{1}{m(E_{r} )} \int _{E_{r}}\left\vert f(y) - f(x) \right\vert \,\mathrm{d} y= 0\text{ and }
		\lim_{r \to 0} \frac{1}{m(E_{r} )} \int _{E_{r}}\left\vert f(y) \right\vert \,\mathrm{d} y= f(x).
	\]
\end{corollary}

\begin{corollary}
	If \(f\in L^1_{\text{loc} }(\mathbb{R} ) \), then \(F(x)= \int_{0}^x f(y)\,\mathrm{d} y\) is differentiable and \(F^\prime (x)=f(x)\) \hyperref[def:mu-almost-everywhere]{almost everywhere}.
\end{corollary}
