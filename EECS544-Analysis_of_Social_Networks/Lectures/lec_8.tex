\lecture{8}{27 Sep. 12:30}{HITS}
\newcommand*{\horzbar}{\rule[.5ex]{2.5ex}{0.5pt}}
\begin{prev}[The diagonalization]
	We see that
	\begin{enumerate}
		\item \autoref{thm:spectral-theorem}: For an \(n\times n\) symmetric matrix \(A = A^{T}\),
		      \[
			      \det(\lambda I - A) = 0
		      \]
		      as known as the \emph{characteristic equation}.
		\item \(u\) is invertible.
		      \[
			      u^{T} = u^{-1}.
		      \]
		      If \(u^{T}u = I\), then
		      \[
			      x = u^{T}u = \begin{pmatrix}
				      \horzbar & u^{T}_1 & \horzbar \\
				      \horzbar & u^{T}_2 & \horzbar \\
				               & \vdots  &          \\
				      \horzbar & v^{T}_n & \horzbar \\
			      \end{pmatrix}\begin{pmatrix}
				      \mid & \mid &        & \mid \\
				      u_1  & u_2  & \cdots & u_n  \\
				      \mid & \mid &        & \mid \\
			      \end{pmatrix}
		      \]
		\item \(A = u^{T} D u\)  where \[
			      D  = \begin{pmatrix}
				      \lambda_1 &           &        &           \\
				                & \lambda_2 &        &           \\
				                &           & \ddots &           \\
				                &           &        & \lambda_n \\
			      \end{pmatrix}.
		      \]
	\end{enumerate}
\end{prev}

\section{Diagonalization}
\begin{eg}
	\[
		A = \begin{pmatrix}
			1 & 0 & 0 \\
			0 & 2 & 1 \\
			0 & a & 2 \\
		\end{pmatrix}.
	\]
	The determinant is
	\[
		\begin{split}
			\det(\lambda I - A) &= \det \left(  \begin{pmatrix}
				\lambda - 1 & 0            & 0             \\
				0           & \lambda -  2 & 1             \\
				0           & 2            & \lambda -   2 \\
			\end{pmatrix}\right)\\
			&= (\lambda - 1)((\lambda - 2 )^2 - a) = (\lambda - 1)(\lambda^2 - 4\lambda + 4 - a).
		\end{split}
	\]
	Since \(\vartriangle = 16 - 4(4-a) = 4a\),  \(a = -1\), \(\vartriangle = -4 < 0 \implies\) complex roots. Hence,
	\[
		A = \begin{pmatrix}
			1 & 0  & 0 \\
			0 & 2  & 2 \\
			0 & -1 & 2 \\
		\end{pmatrix}
	\] has complex roots.
\end{eg}

\begin{definition}[Laplician]
	For an undirected graph, the \emph{Laplician} is defined as \(L = D - A\), where \(A\) is adjacent matrix, \(D\) is diagonal degree matrix.
\end{definition}
\begin{remark}
	Since \[
		L^{T} = (D - A)^{T} = D^{T} - A^{T} = D - A = L.
	\] We see that the eigenvalues are real. Many incidence matrices \(B\ (V\times  E)\),
	\[
		L = BB^{T} \text{ for any choices of }B.
	\]
	\(L\) has non-negative eigenvalues.
\end{remark}

\section{Positive Definite and Positive Semi-Definite}
\begin{definition}[Positive definite]
	\(A \) is \emph{positive definite} (PD) if and only if
	\[
		\forall \vec{x} \neq  \vec{0},\quad \vec{x}^{T}A \vec{x} > 0.
	\]
\end{definition}

\begin{definition}[Positive semi-definite]
	\(A \) is \emph{positive semi-definite} (PSD) if and only if
	\[
		\forall \vec{x} \neq  \vec{0},\quad \vec{x}^{T}A \vec{x} \geq  0.
	\]
\end{definition}

\begin{remark}
	If \(\lambda\) is a real eigenvalue, then if \(\lambda \geq  0, A \text{ is PSD}\); \(\lambda > 0, A \text{ is PD}\).
\end{remark}
\begin{explanation}
	Suppose \(\lambda\) is a real eigenvalue, let \(\vec{u}\) be the eigenvector such that
	\[
		A \vec{u} = \lambda \vec{u},
	\]
	and
	\[
		\vec{u}^{T} A \vec{u} = \vec{u}^{T} (\lambda \vec{u}) = \lambda \underbrace{\vec{u}^{T}\vec{u}}_{>0} \geq 0\implies(\text{PSD})
	\]
	also, if \(\lambda \vec{u}^{T} \vec{u} > 0\), then PD.

	Then, we have \(A\) is PSD and symmetric \(\iff \exists \vec{B}\) such that \(A = \vec{B} \vec{B}^{T}\),
	\[
		x^{T} A x = x^{T} \vec{B} \vec{B}^{T} x = (\vec{B}x)^{T} \vec{B}x = y^{T} y \geq 0.
	\]

	Laplacian \(L = B B^{T}\) (incidence matrix)
	\[
		\implies L \text{ is PSD}\implies 0 \leq \lambda_1 \leq \lambda_2 \leq \ldots \leq \lambda_n.
	\]
	But \(\lambda_1 = 0\), \(0\) is coming from
	\[
		L = D-A, D = \begin{pmatrix}
			d_1 &        &     \\
			    & \ddots &     \\
			    &        & d_n \\
		\end{pmatrix}\implies L \vec{1} = (D - A)\vec{1} = \begin{pmatrix}
			d_1    \\
			d_2    \\
			\vdots \\
			d_n    \\
		\end{pmatrix} - A\vec{1} = \vec{0}\implies L \vec{1} = 0 \vec{1}.
	\]
	Hence, \(0\) is an eigenvalue with eigenvector \(\vec{1}\).
\end{explanation}

\begin{note}
	Study the multiplicity of \(0\) as an eigenvalue of \(L\)
	\[
		\det(\lambda I - A) = (\lambda - a_1)(\lambda - a_2)\cdots (\lambda - a_n)
	\]
	where \(a_i\cdots \)
\end{note}

\begin{definition}[Fiedler eigenvalue]
	Find Laplacian, do the eigen-decomposition, find all that are close to zero.
\end{definition}

The eigenvectors can be used to find communities, and community detection algorithm rely on this fact.

\begin{prev}
	Givran-Newman algorithm
\end{prev}
\begin{problem}
Hyper link(directed): How important is the edge?
\end{problem}
\begin{answer}
	Search seems to rank nodes, not edges.
\end{answer}

\begin{problem}
How does one rank nodes?
\end{problem}
\begin{answer}
	Network Centrality.
\end{answer}

\begin{eg}
	Many examples.
	\begin{itemize}
		\item Degree. Ranks nodes by edges
		\item Eigen centrality. \(A\): adjacency matrix, finds an eigenvector and use its entries.
	\end{itemize}
\end{eg}

\chapter{HITS (Jon Kleinberg)}
HITS: hyper-link induced topic search.

Hubs and authorities.
\begin{itemize}
	\item Hubs: nodes that \emph{aggregate}
	\item Authorities: nodes that are \emph{important}.
\end{itemize}

Key ideas:
\begin{enumerate}
	\item If many websites (nodes) point to it, then this website is important (authority property)
	\item If a node points to many authority nodes, then it is important as well.
\end{enumerate}

Iteratively identity hubs \& authorities, then repeat.

Each node \(v\) has two scores.
\begin{enumerate}
	\item \(\texttt{auth}(v)\)
	\item \(\texttt{hub}(v)\)
\end{enumerate}

\section{HITS-Algorithm}
\begin{enumerate}
	\item Initialize: \(\texttt{auth}(v) = \texttt{hub}(v) \equiv 1, \forall v\in V\)
	\item Authority updates:
	      \begin{itemize}
		      \item \(\texttt{auth}(v) = \) sum of this hub scores of the nodes that point to it
	      \end{itemize}
	\item Hub updates:
	      \begin{itemize}
		      \item \(\texttt{hub}(v) = \) sum of all authority scores of the nodes that it points to.
	      \end{itemize}
	\item Normalize the scores:
	      \begin{itemize}
		      \item \(\texttt{hub}(v) = \frac{\texttt{hub}(v)}{\sum\limits_{u\in V} \texttt{hub}(u) }\)
		      \item \(\texttt{auth}(v) = \frac{\texttt{auth}(v)}{\sum\limits_{u\in V} \texttt{auth}(u) }\)
	      \end{itemize}
	\item Repeat from 2(as many times, hoping for a convergence)
\end{enumerate}

\begin{note}
	There are two facts are worth noting.
	\begin{enumerate}
		\item \(\texttt{hub}(v)\) \& \(\texttt{auth}(v)\) will converge as long as initial score are positive.
		\item Final scores will be independent of the initial scores.
	\end{enumerate}
\end{note}
