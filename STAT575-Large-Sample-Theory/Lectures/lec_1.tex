\chapter{Introduction}
\lecture{1}{21 Aug.\ 9:00}{Introduction to Mathematical Statistics}
\section{What is Empirical Process Theory?}
This subject started in the 1930s with the study of the \hyperref[def:empirical-CDF]{empirical CDF}.

\begin{definition}[Empirical CDF]\label{def:empirical-CDF}
	Given inputs i.i.d.\ data points \(X_1, \dots , X_n \sim \mathbb{P} \), the \emph{empirical CDF} is
	\[
		F_n(t) = \frac{1}{n} \sum_{i=1}^{n} \mathbbm{1}_{X_i \leq t} .
	\]
\end{definition}

The classical result is that, fixing \(t\), \(F_n(t) \to F(t)\) almost surely.

\begin{note}
	At the same time, \(\sqrt{n} (F_n(t) - F(t)) \to \mathcal{N} (0, F(t)(1 - F(t)))\) in distribution.
\end{note}

On the other hand, we can also ask does this convergence happens if we jointly consider all possible \(t\in \mathbb{R} \). By the \href{https://en.wikipedia.org/wiki/Glivenko-Cantelli_theorem}{Glivenko-Cantelli theorem}, \(\sup _{t \leq\mathbb{R} } \vert F_n(t) - F(t) \vert \overset{n \to \infty }{\to } 0\) almost surely, so the answer is again yes.

Now, we're ready to see a ``canonical'' example of an \hyperref[def:EP]{empirical process}.

\begin{eg}[Canonical empirical process]
	The \emph{canonical empirical process} is the family of random variables \(\left\{ F_n(t) \right\}_{t\in \mathbb{R} } \), i.e., a stochastic process.
\end{eg}

By considering a general class of functions, we have the following.

\begin{definition}[Empirical process]\label{def:EP}
	Let \(\chi \) be the domain, \(\mathbb{P} \) be a distribution on \(\chi \), and \(\mathscr{F} \) be the class of function such that \(\chi \to \mathbb{R} \). The \emph{empirical process} is the stochastic process indexed by functions in \(\mathscr{F} \), \(\left\{ G_n(f) \colon f\in \mathscr{F}  \right\} \) where
	\[
		G_n(f) = \frac{1}{n} \sum_{i=1}^{n} f(X_i) - \mathbb{E}_{}\left[f(X) \right]
	\]
	and \(X_1, \dots , X_n \overset{\text{i.i.d.} }{\sim } \mathbb{P} \).
\end{definition}

\begin{remark}
	The \hyperref[def:EP]{empirical process} is a family of mutually dependent random variables, all of them being functions of the same inherent randomness in the i.i.d.\ data \(X_1, \dots , X_n \).
\end{remark}

Now, two questions arise.

\subsection{Uniform Law of Large Numbers}
As \(n \to 0\), whether
\[
	S_n(\mathscr{F} ) \coloneqq \sup _{f\in \mathscr{F} } \vert G_n(f) \vert \to 0,
\]
and if so, at what rate?

\begin{remark}
	The rate of convergence of the law of large numbers uniformly over a class of functions \(\mathscr{F} \) determines the performance of many types of statistical estimators as we will see.
\end{remark}

We will spend most of this course just on this topic with applications. We will show that \(S(\mathscr{F} )\) concentrates around its expectation and will bound \(\mathbb{E}_{}\left[S(\mathscr{F} ) \right] \).

\subsection{Uniform Central Limit Theorem}
The most general probabilistic question one can ask is the following.

\begin{problem*}
	What is the joint distribution of the \hyperref[def:EP]{empirical process}?
\end{problem*}
\begin{answer}
	For a given sample size, it's most often intractable to be able to calculate the joint distribution exactly. One can then use asymptotics when the sample size \(n\) is very large to derive limiting distributions. By the regular central limit theorem, \(\sqrt{n} G_n(f) \overset{d}{\to} \mathcal{N} (0, \Var_{}\left[f(X) \right] )\).for any \(f\). We want to understand if this holds uniformly (jointly) over \(f\in \mathscr{F} \) in some sense.
\end{answer}

We first motivate this through an example.

\begin{eg}[Uniform empirical process]
	Consider
	\begin{itemize}
		\item \(X_1, \dots , X_n\) i.i.d.\ from \(\mathcal{U} (0, 1)\).\footnote{\(\mathcal{U}\) denotes the uniform distribution.}
		\item \(\mathscr{F} = \left\{ \mathbbm{1}_{[-\infty , t]} \colon t\in \mathbb{R}  \right\} \)
		\item \(U_n(t) = \sqrt{n} (F_n(t) - t) \) where \(F_n\) is the \hyperref[def:empirical-CDF]{empirical CDF}.
	\end{itemize}
	We can view \(U_n(t) \) as a collection of random variables one for each \(t\in (0, 1)\), or just as a random function. Then this stochastic process \(\left\{ U_n(t)\colon t\in (0, 1) \right\} \) is called the \emph{uniform empirical process}.

	Then, the CLT states that for each \(t\in [0, 1]\), \(U_n(t) \to \mathcal{N} (0, t - t^2)\) as \(n \to \infty \). Moreover, for fixed \(t_1, \dots , t_k\), the multivariate CLT implies that \((U_n(t_1), \dots , U_n(t_k)) \overset{d}{\to } \mathcal{N} (0, \mathbf{\Sigma} ) \) where \(\mathbf{\Sigma} _{ij} = \min (t_i, t_j) - t_i t_j\).
\end{eg}

From this example, one can ask questions like the following.

\begin{problem*}
	Does the entire process \(\left\{ U_n(t)\colon t\in [0, 1] \right\} \) converge in some sense? If so, what is the limiting process?
\end{problem*}
\begin{answer}
	The limiting process is an object called the \emph{Brownian Bridge}. This was conjectured by Doob and proved by Donsker.
\end{answer}

Other than that, how do we characterize the convergence of stochastic processes in distribution to another stochastic process? How do we generalize this result for a general function class \(\mathscr{F} \) defined on a probability space \(\chi \)? What are some statistical applications of such process convergence results? This is a classical topic and in the last few weeks of this course, we will touch upon some of these questions.

\section{Applications of Uniform Law of Large Numbers}
Next, we see one major example where the uniform law of large numbers can be applied.

\subsection{\(M\)-Estimators}\label{subsec:M-estimators}
Consider the class of estimators called ``\(M\)-estimator'', which is of the form
\[
	\hat{\theta} = \argmin_{\theta \in \Theta } \frac{1}{n} \sum_{i=1}^{n} M_\theta (X_i),
\]
where \(X_1, \dots , X_n \) taking values in \(\chi \), \(\Theta \) is the parameter space, and \(M_\theta \colon \chi \to \mathbb{R} \) for each \(\theta \in \Theta \). Let's see some examples.

\begin{eg}[Maximum log-likelihood]
	\(M_\theta (X) = - \log p_\theta (X)\) for a class of densities \(\left\{ p_\theta \colon \theta \in \Theta  \right\} \), then \(\hat{\theta} \) is the \emph{Maximum log-likelihood} of \(\theta \).
\end{eg}

There are lots of examples of ``local estimators'' as well.

\begin{eg}[Mean]
	\(M_\theta (x) = (x-\theta )^2\).
\end{eg}

\begin{eg}[Median]
	\(M_\theta (x) = \vert x - \theta  \vert\).
\end{eg}

\begin{eg}[\(\tau \) quantile]
	\(M_\theta (x) = Q_{\tau } (x - \theta )\) where \(Q_\tau (x) = (1 - \tau ) x \mathbbm{1}_{x < 0} + \tau x \mathbbm{1}_{x\geq 0} \).
\end{eg}

\begin{eg}[Mode]
	\(M_\theta (x) = - \mathbbm{1}_{\vert X - \theta  \vert \leq 1}\).
\end{eg}

Now, the target quantity for the estimator \(\hat{\theta} \) is
\[
	\theta _0 = \argmax_{\theta \in \Theta } \mathbb{E}_{}\left[M_\theta (X_1) \right]
\]
where \(X_1, \dots , X_n \overset{\text{i.i.d.} }{\sim }\mathbb{P} \). In the asymptotic framework, the two key questions are the following.

\begin{problem*}
	Is \(\hat{\theta} \) consistent for \(\theta _0\)? Does \(\hat{\theta} \) converge to \(\theta _0\) almost surely or in probability as \(n\to \infty \)? I.e., is \(d(\hat{\theta} , \theta _0)\to 0\) for some metric \(d\)?
\end{problem*}

\begin{problem*}
	What is the rate of convergence of \(d(\hat{\theta} , \theta _0)\)? For example is it \(O(n^{-1 / 2})\) or \(O(n^{-1 / 3})\)?
\end{problem*}

To answer these questions, one is led to investigate the closeness of the empirical objective function to the population objective function in some uniform sense. Consider \(M_n(\theta ) = \frac{1}{n} \sum_{i=1}^{n} M_\theta (X_i)\) and \(M(\theta ) = \mathbb{E}_{}\left[M_\theta (X_1) \right] \), then
\[
	\begin{split}
		\mathbb{P} (d(\hat{\theta} , \theta _0) > \epsilon )
		 & \leq \mathbb{P} \left( \sup _{\theta \colon d(\theta , \theta _0) > \epsilon } M_n(\theta _0) - M_n(\theta ) \geq 0\right)                                                                                                                              \\
		 & = \mathbb{P} \left( \sup _{\theta \colon d(\theta , \theta _0) > \epsilon } \left( M_n(\theta _0) - M(\theta _0) - [M_n(\theta ) - M(\theta )] \right) \geq \inf _{\theta \colon d(\theta , \theta _0) > \epsilon } (M(\theta ) - M(\theta _0)) \right) \\
		 & \leq \mathbb{P} \left( 2 \sup_{\theta \in \Theta } \vert M_n(\theta ) - M(\theta ) \vert \geq \inf _{\theta \colon d(\theta , \theta _0) > \epsilon } (M(\theta ) - M(\theta _0)) \right) .
	\end{split}
\]

We see that the left-hand side \(2 \sup _{\theta \in \Theta } \vert M_n(\theta ) - M(\theta ) \vert \) is just \(S(\mathscr{F} )\) for \(\mathscr{F} = \left\{ f_\theta \colon \theta \in \Theta , f_\theta = M_\theta (\cdot) \right\} \), while the right-hand side \(\inf_{\theta \colon d(\theta , \theta _0) > \epsilon } M(\theta ) - M(\theta _0)\) is larger than \(0\).

\begin{remark}
	The last step could be too loose in some problems.
\end{remark}