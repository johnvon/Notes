\lecture{23}{01 Dec. 08:00}{Branch and Bound}
\section{Branch and Bound}
\begin{prev}
	The worst case in terms of time complexity for Simplex Algorithm is
	\[
		\Theta(2^n - 1)
	\]
	for \(n\) variables, but it's efficient in practice. And this is similar to
	the Branch and Bound Algorithm for the integral programming problem.
\end{prev}

We now focus on the following integer programming,
\begin{align*}
	\max~                   & y^{T}b                                                                                              \\
	                        & y^{T}A\leq c^{T}                                                                                    \\
	(D_{\mathcal{I} })\quad & y\in\mathbb{\MakeUppercase{R}}^m(y_{i}\in\mathbb{\MakeUppercase{Z}} \text{ for } i\in \mathcal{I}),
\end{align*}
where \(\mathcal{I} \subseteq \{1, 2, \ldots , m\}\). By taking the dual, we have
\begin{align*}
	\min~    & c^Tx     \\
	         & Ax = b   \\
	(P)\quad & x\geq 0.
\end{align*}

We'll see that the branch and bound algorithm maintains the following:
\begin{itemize}
	\item \(\mathcal{L} \): A list \(\mathcal{L} \) of \emph{subproblems} that have the form of \(D_{\mathcal{I} }\).
	\item \(\mathrm{LB} \): The current best lower bound on \(z\) such that \(\mathrm{LB}\leq z \).
	\item \(\overline{y}_{\mathrm{LB}}\): The \(\overline{y}\) corresponds to \(\mathrm{LB}\).
\end{itemize}

\begin{note}
	\(\mathrm{LB} \) is the objective value of the best feasible solution to the original problem seen so far. And we'll set
	\[
		\mathrm{LB} \coloneqq  -\infty
	\]
	if there is no known feasible solution.
\end{note}
\begin{remark}
	The key property of \(\mathcal{L} \) is that if there is a feasible solution to the original problem that is better than
	\(\mathrm{LB} \), it should be feasible for some subproblem on \(\mathcal{L} \).

	\par Initially, we have
	\[
		\mathcal{L} \coloneqq \left\{D_{\mathcal{I}}\right\}.
	\]

	\par And we stop if
	\[
		\mathcal{L} = \varnothing,
	\]
	since this implies \(z = \mathrm{LB} \).
\end{remark}

The general procedure is to take some problem \(\widetilde{D}_{\mathcal{I}}\) from \(\mathcal{L}\) and remove it, and then solve
its linear programming \(\widetilde{D}\). Then we see
\begin{itemize}
	\item If \(\widetilde{D}\) is infeasible, then do nothing.
	\item Otherwise, let \(\overline{y}\) be its basic optimal solution.
	      \begin{itemize}
		      \item If \(\overline{y}^{T}b\leq \mathrm{LB}\), then do nothing.
		      \item Otherwise,
		            \begin{itemize}
			            \item If \(\overline{y}^{T}_i\in\mathbb{\MakeUppercase{Z}}\) for \(i\in \mathcal{I}\), then \(\overline{y}\) solves \(\widetilde{D}_{\mathcal{I}}\).
			                  Let
			                  \[
				                  \mathrm{LB} \coloneqq \overline{y}^{T}b \text{ and } \overline{y}_{\mathrm{LB}}\coloneqq \overline{y}.
			                  \]
			            \item If \(\overline{y}^{T}_{i}\notin \mathbb{\MakeUppercase{Z}}\) for some \(i\in \mathcal{I} \),
			                  \begin{itemize}
				                  \item Select \(i\in \mathcal{I} \) such that \(\overline{y}_{i}\notin \mathbb{\MakeUppercase{Z}}\).
				                  \item Place two \emph{child} problems on \(L\):

				                        \begin{enumerate}
					                        \item \emph{Down branch}: \(\widetilde{D}_{\mathcal{I}}\) with
					                              \[
						                              y_{i}\leq \left\lfloor \overline{y}_{i} \right\rfloor.
					                              \]
					                        \item \emph{Up branch}: \(\widetilde{D}_{\mathcal{I}}\) with
					                              \[
						                              y_{i}\geq \left\lceil \overline{y}_{i} \right\rceil.
					                              \]
					                              \begin{note}
						                              To match the form, we use \(-y_{i}\leq -\left\lceil \overline{y}_{i}\right\rceil\).
					                              \end{note}
				                        \end{enumerate}
			                  \end{itemize}
		            \end{itemize}
	      \end{itemize}
\end{itemize}

Process: \(\widetilde{D}_{\mathcal{I}}\)(problem chosen from \(\mathcal{L}\))
\begin{itemize}
	\item Solve linear programming relaxation \(\widetilde{D}\)
	      \[
		      \begin{alignedat}{5}
			      \max ~&y^{T}b\qquad\qquad	&&\min~		&&c^{T}x\\
			      &y^{T}A\leq c^{T} 		&&			&&Ax = b\\
			      (D)\quad	& 				&&(P)\quad	&&x\geq  0
		      \end{alignedat}.
	      \]
	      What we're really doing is solving \(P\) by simplex algorithm. Let \(\overline{y}^{T}\coloneqq c^{T}_{\beta}A^{T}_{\beta}\).
	      \begin{itemize}
		      \item \emph{Down branch}:
		            \[
			            \begin{alignedat}{5}
				            \max ~	&y^{T}b\qquad\qquad				&&\min~	&&c^{T}x+\left\lfloor \overline{y}_{i} \right\rfloor x_{down}\\
				            &y^{T}A\leq c^{T} 				&&		&&Ax + e_{i}x_{down} = b\\
				            (D)\quad& y_{i}\leq \left\lfloor \overline{y}_{i} \right\rfloor	&&(P)\quad&&x\geq 0, x_{down}\geq 0.
			            \end{alignedat}
		            \]
		            The reduced cost of \(x_{down}\) is
		            \[
			            \left\lfloor \overline{y}_{i} \right\rfloor - \overline{y}^{T}e_{i} = \left\lfloor \overline{y}_{i} \right\rfloor - \overline{y}_{i}.
		            \]
		            If this is negative, then \(x_{down}\) enters the basis, which happens when \(\overline{y}_{i}\notin\mathbb{\MakeUppercase{Z}}\).
		      \item \emph{Up branch}:
		            \begin{align*}
			            \min~ & c^Tx  - \left\lceil \overline{y}_{i} \right\rceil x_{up} \\
			                  & Ax - e_{i}x_{up}= b                                      \\
			                  & x\geq 0, x_{up}\geq 0.
		            \end{align*}
		            The reduced cost of \(x_{up}\) is
		            \[
			            -\left\lceil \overline{y}_{i} \right\rceil - \overline{y}^{T}(-e_{i}) = \overline{y}_{i} - \left\lceil \overline{y}_{i} \right\rceil.
		            \]
		            If this is negative, then \(x_{up}\) enters the basis.
	      \end{itemize}
	      \begin{remark}
		      In practice,
		      \begin{itemize}
			      \item When we solve a child, our best wish is that optimal value \(\leq \mathrm{LB}\).(then we don't have to branch)
			      \item As we solve the child, we can stop once its objective value is at or below \(\mathrm{LB} \).
		      \end{itemize}
	      \end{remark}
\end{itemize}

\subsection{Global Upper Bound}
Since in practice, there are many errors in the data, so we may just want to solve it approximately, which means we only want to get a global upper bound.
Conceptually,
\[
	\mathrm{UB} \coloneqq \max\left\{\mathrm{LB}, \max\left\{\text{\(\mathrm{LP}\) relaxation values for all problems on \(\mathcal{L}\) }\right\}\right\}
\]
To calculate the set in the \(\max\), whenever children are created, solve their LP relaxation upon insertion into list. And we stop if
\[
	\mathrm{UB} - \mathrm{LB} < \text{absolute tolerance}.
\]

\begin{remark}
	Apparently, we see that we can do this by reordering the algorithm. But for the original algorithm, we don't care about \(\mathrm{UB}\).
\end{remark}

\subsection{Node Selection}
Node Selection means which problem to select from \(\mathcal{L} \) to process. There are several ways to do this.
\begin{enumerate}
	\item FIFO(First In First Out) \(\cong\) BFS(Breadth First Search)
	      \par New problems go at the end of the list, select from the front. We see that this strategy will \textbf{maximize memory usage}.
	\item LIFO(Last In First Out) \(\cong\) DFS(Depth First Search)
	      \par New problems go to the first of the list, select from the front. We see that this strategy will \textbf{increase \(\mathrm{LB}\) quickly}.
	\item Best Bound.
	      \par Need the LP upper bound for all problems on the list. We see that this strategy will \textbf{decrease \(\mathrm{UB}\) quickly}.
\end{enumerate}

\begin{remark}
	For any reasonable solver, it will first do the second strategy for several times, and they exclusively do the third strategy.
\end{remark}

\subsection{Choosing Branching Variable}
\begin{enumerate}
	\item Random: Choose randomly among \(y_{i}\) such that \(\overline{y}_{i}\notin\mathbb{\MakeUppercase{Z}}\).
	\item Biggest Cost: Choose based on the biggest \(c_{i}\).
	\item Most Fractional: Choose \(i\) with \(\overline{y}_{i}\) \emph{most fractional}.
	\item \textbf{Pseudo Cost Branching}
\end{enumerate}

\begin{note}
	Someone argues that the \emph{most fractional} rules is as bad as choosing randomly.
\end{note}
