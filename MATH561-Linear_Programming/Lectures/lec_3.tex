\chapter{Production Problem}
\lecture{3}{8 Sep. 08:00}{Production Problem}
\section{Production Problem}
Skip.\todo{add this!!!}
\section{Norm}
Define
\begin{itemize}
	\item maximum norm as
	      \[
		      \left\lVert x\right\rVert_{\infty } \coloneqq \max_{1\leq i \leq n}\{\left\vert x_i \right\vert \}
	      \]
	\item 1-norm as
	      \[
		      \left\lVert x\right\rVert_{1} \coloneqq \sum\limits_{i=1}^{n} \left\vert x_i \right\vert
	      \]
	\item 2-norm as
	      \[
		      \left\lVert x\right\rVert_{2} \coloneqq \sqrt{\sum\limits_{i=1}^{n} x_i^2}
	      \]
\end{itemize}
we can easily find the respective norm for \(x\) by following linear optimization problems.

\subsection{Maximum(Infinity) Norm}
Consider
\begin{align*}
	\min~ & \left\lVert x\right\rVert_{\infty } \\
	      & Ax = b,
\end{align*}
we set up
\begin{align*}
	\min~ & t                                      \\
	      & t\geq x_i,\text{ for }i = 1, \ldots ,n \\
	      & t\leq x_i,\text{ for }i = 1, \ldots ,n \\
	      & Ax = b.
\end{align*}

We see that the linear optimization \emph{pressure} will force the maximum of \(\left\vert x_i \right\vert \) being small, hence
we'll get the minimum among \(\left\vert x_i \right\vert \).

\subsection{1-Norm}
Consider
\begin{align*}
	\min~ & \left\lVert x\right\rVert_1 \\
	      & Ax = b,
\end{align*}
we set up
\[
	\begin{alignedat}{3}
		\min~ & \sum\limits_{i=1}^{n} t_i                \\
		& t_i\geq x_i, && \text{ for }i = 1, \ldots ,n  \\
		& t_i\leq -x_i, && \text{ for }i = 1, \ldots ,n \\
		& Ax = b.
	\end{alignedat}
\]

Again, we see that the linear optimization pressure will force \(t_i\) goes to \(\left\vert x_i \right\vert \), resulting
\(\sum\limits_{i=1}^{n} t_i\) being \(\left\lVert x\right\rVert_1\).

\begin{remark}
	Minimize \(\left\lVert x\right\rVert_1\) tends to make \(x\) \textbf{spars}(lots of zeros).
	\begin{figure}[H]
		\centering
		\incfig{1-norm}
		\caption{The best approximated convex function of \(I_{x = 0}\) }
		\label{fig:1-norm}
	\end{figure}
\end{remark}
