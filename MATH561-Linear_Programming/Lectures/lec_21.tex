\lecture{21}{22 Nov. 08:00}{Cutting-Stock Problem}
\section{Cutting-Stock Problem}
It's now a good timing to introduce an application of what we have been discussing, namely the \emph{Cutting-Stock Problem}. We'll see
that it naturally utilize the idea of column generation.

\begin{problem}
Contrarily, \emph{Cutting-Stock Problem} can be nicely approximated by \textbf{rounding down}. Consider we have rolls of paper of width
\(W\), with the demand widths being \(w_1, w_2, \ldots , w_m < W\) and demands being \(d\), which is usually
pretty big. The goal is to use as few stock rolls as possible.

\begin{answer}
	One may try to define
	\[
		x_{ij}\coloneqq \# \text{ of rolls of width \(w_{i}\) to cut from stock roll \(j\)}.
	\]
	But we immediately see that the number of variables is huge for an integer programming, hence this doesn't work. Instead, we
	denote a \emph{pattern} as a vector \(a\) being
	\[
		a \coloneqq \begin{pmatrix}
			a_1    \\
			a_2    \\
			\vdots \\
			a_m    \\
		\end{pmatrix},
	\]
	where \(a_{i} = \#\text{ of pieces of width \(w_{i}\) to cut using this pattern}\). Then the constraints for a pattern is
	\begin{align*}
		 & \sum\limits_{i=1}^{m} w_{i}a_{i}\leq W                                   \\
		 & \mathbb{\MakeUppercase{N}}\ni a_{i}\geq 0 \text{ for }i = 1, \ldots , m.
	\end{align*}
	Moreover, denotes \(d\) as
	\[
		d\coloneqq \begin{pmatrix}
			d_1    \\
			d_2    \\
			\vdots \\
			d_m    \\
		\end{pmatrix},
	\]
	then the Cutting-Stock problem is simply
	\begin{align*}
		z\coloneqq \min~    & \sum\limits_{j} x_{j}                  \\
		                    & \sum\limits_{j} A_{\cdot j}x_{j}\geq d \\
		(\mathrm{CSP})\quad & x_{j}\geq 0 \text{ integer for all }j,
	\end{align*}
	where
	\[
		A_{\cdot j} = \begin{pmatrix}
			a_{1j} \\
			a_{2j} \\
			\vdots \\
			a_{mj} \\
		\end{pmatrix}.
	\]

	Turning \(\mathrm{CSP}\) into a standard form problem and \textbf{drop} the integer constraint, we have
	\begin{align*}
		\min~                           & \sum\limits_{j} x_{j}                                                         \\
		                                & \sum\limits_{j} A_{\cdot j}x_{j} - t = d                                      \\
		(\mathrm{\underline{CSP}})\quad & x_{j}\geq 0 \text{ for all }j,\ t_{i}\geq 0\text{ for all }i = 1, \ldots , m.
	\end{align*}

	\begin{note}
		\(\mathrm{\underline{CSP}}\) gives a lower bound on \(\mathrm{CSP}\). Moreover, the constraint of \(x_{j}\in\mathbb{\MakeUppercase{N}}\)
		is now gone.
	\end{note}

	We now want to solve \(\mathrm{\underline{CSP}}\) exactly to get optimum \(\overline{x}, \overline{t}\) with value
	\(\underline{z} = \sum\limits_{i=1}^{m} \overline{x}_{i}\).

	Firstly, if we round up \(\overline{x}\) to \(\left\lceil \overline{x} \right\rceil \), then it is feasible for \(\mathrm{CSP}\).
	We immediately see
	\[
		\sum\limits_{i=1}^{m} \overline{x}_{i} = \underline{z} \leq z \leq \sum\limits_{i=1}^{m} \left\lceil \overline{x}_{i} \right\rceil.
	\]
	Since we also have
	\[
		\left\lceil \sum\limits_{i=1}^{m} \overline{x}_{i} \right\rceil \leq z,
	\]
	hence we see that the rounding up solution \(\left\lceil \overline{x} \right\rceil \) is within \(m-1\) of optimum.

	Now we consider how to solve \(\mathrm{\underline{CSP}}\) exactly. Denotes the dual variables of \(\mathrm{\underline{CSP}}\) being \(y\)
	such that
	\[
		y = \begin{pmatrix}
			y_1    \\
			\vdots \\
			y_{m}  \\
		\end{pmatrix}.
	\]
	Suppose \(\overline{y}\) is a basic dual solution. Then the reduced cost of a variable is:
	\begin{itemize}
		\item \(t_{i}\):
		      \[
			      0 - \overline{y}^{T}(-e_{i}) = \overline{y}_{i}.
		      \]
		      Hence, if \(\overline{y}_{i}<0\), \(t\) can enter the basis.
		\item \(x_{j}\):
		      \[
			      1 - \overline{y}^{T}A_{\cdot j} = 1 - \sum\limits_{i=1}^{m} \overline{y}_{i}a_{ij}.
		      \]
		      If this is \(<0\), then \(x_{j}\) can enter the basis. To drive some quantity negative, we simply set up a minimization problem.
		      Specifically, we set up a linear program such that
		      \begin{align*}
			      \min~ & 1 - \sum\limits_{i=1}^{m} \overline{y}_{i}a_{ij} \\
			            & \sum\limits_{i=1}^{m} w_{i}a_{ij}\leq W          \\
			            & a_{ij}\geq 0 \text{ integers}.
		      \end{align*}
		      Equivalently,
		      \begin{align*}
			      1 - \max~ & \sum\limits_{i=1}^{m} \overline{y}_{i}a_{i}         \\
			                & \sum\limits_{i=1}^{m} w_{i}a_{i}\leq W              \\
			                & a_{i}\geq 0 \text{ integers for }i = 1, \ldots , m.
		      \end{align*}
		      This is just a \emph{Knapsack problem}. Now, let \(f(S)\) being the optimal value for Knapsack of capacity \(S\) such that
		      \(S = 0, 1, \ldots , W\). We see that
		      \[
			      \begin{split}
				      f(0) &= 0\\
				      &\vdots\\
				      f(S) &= \max_{i\colon w_{i}\leq S}\left\{ \overline{y}_{i} + f(S - w_{i})\right\}\\
				      &\vdots\\
				      f(W) &= \text{ solution}.\\
			      \end{split}
		      \]
		      The running time is \(\Theta(Wm)\).
		      \begin{note}
			      Note that we assume \(W\) and \(w_{i}\) are integer.
		      \end{note}
		      Notice that the above only gives \(f(W)\), which is the objective value, but without information for variables. We can retrieve the
		      information by keeping tracking of the argument of maximum in each step, namely we record
		      \[
			      \begin{split}
				      i^{*}_{0 }\to f(0) &= 0\\
				      &\vdots\\
				      i^{*}_S \to f(S) &= \max_{i\colon w_{i}\leq S}\left\{ \overline{y}_{i} + f(S - w_{i})\right\}\\
				      &\vdots\\
				      i^{*}_W \to f(W) &= \text{ solution}.\\
			      \end{split}
		      \]
		      Then we simply \emph{back-track} every \(i^{*}\) from \(i^{*}_W\), and then the next one is simply \(i^{*}_{W - w_{i^{*}_W}}\), and
		      so on.
	\end{itemize}
\end{answer}
\end{problem}