\lecture{11}{6 Oct. 08:00}{Duality}
\begin{prev}[The production problem]
	Recall the \hyperref[subsec:production-problem]{production problem}, where we have
	\[
		\begin{aligned}
			\max~ & c^{\top}x     \\
			      & Ax \leq b     \\
			      & x\geq \vec{0}
		\end{aligned}
	\]
	\begin{itemize}
		\item \(n\) products activities
		\item \(c_{j}=\) per-unit revenue for activity \(j = 1\dots n\)
		\item \(b_{i}=\) resource endowment for resource \(i = 1\dots m\)
		\item \(a_{ij}=\) amount of resource \(i\) consumed by activity \(j\)
	\end{itemize}
	Then we have the \hyperref[def:dual]{dual} as
	\[
		\begin{aligned}
			\min~ & y^{\top}b               \\
			      & y^{\top} A\geq  \vec{c} \\
			      & y\geq \vec{0}
		\end{aligned}
	\]
	where \[
		y^{\top}A_{\cdot j}\geq c_{j} \left( \sum\limits_{i=1}^{m} y_{i}a_{ij} \right) \geq c_{j}.
	\]
\end{prev}

\begin{note}
	We have
	\[
		\begin{array}{rl|ll}

			                                & \min          & \max          &                                \\
			\cline{2-3}
			\ldelim\{{3}{20mm}[constraints] & \geq          & \geq 0        & \rdelim\}{3}{3mm}[variables]   \\
			                                & \leq          & \leq 0        &                                \\
			                                & =             & \mbox{unres.} &                                \\
			\cline{2-3}
			\ldelim\{{3}{17mm}[variables]   & \geq 0        & \leq          & \rdelim\}{3}{3mm}[constraints] \\
			                                & \leq 0        & \geq          &                                \\
			                                & \mbox{unres.} & =             &                                \\
		\end{array}
	\]
	for a general rule to find a \hyperref[def:primal]{primal}'s \hyperref[def:dual]{dual}.
\end{note}

Come back to \hyperref[def:complementary]{complementary}.
\[
	\begin{split}
		\hat{y}^{\top} A_{\cdot j} - c_{j}\hat{x}_j = 0 &\text{ for }j = 1\dots n\\
		\hat{y}_i(b_{i} - A_{i\cdot }x) = 0 &\text{ for }i = 1\dots m\\
	\end{split}
\]

\begin{note}
	For \hyperref[def:feasible-solution]{feasible solutions} of \((\mathrm{P})\) and \((\mathrm{D})\), at most one of \(\hat{y}A_{\cdot j} - c_{j}\) and \(\hat{x}_j\) is positive for \(j = 1\dots n\);
	while at most one of \(b_{i} - A_{\cdot j}\hat{x}\) and \(\hat{y}_j\) is positive for \(i = 1\dots m\);
\end{note}

\begin{problem}
We are looking for a way to find out the upper bound of \(c^{\top}x\) from the \hyperref[def:dual]{dual}.
\end{problem}
\begin{answer}
	Since
	\[
		c^{\top}x \underset{?}{\leq}
		\underbrace{y^{\top} A }_{\geq c^{\top}}\underbrace{\vphantom{y^{\top}A}x}_{\geq \vec{0}}
		\leq \underbrace{y^{\top}}_{\geq \vec{0}} b
		\iff \sum\limits_{i=1}^{m} y_{i} \left( \sum\limits_{j=1}^{n} a_{ij}x_{j} \right)
		\leq \sum\limits_{i=1}^{m} y_{i}b_{i}.
	\]

	We want
	\[
		c^{\top}\leq y^{\top}A\implies c^{\top}x\leq y^{\top} Ax
	\]

	Now, return to the \hyperref[def:standard-form]{standard form} problem, we have
	\[
		\begin{alignedat}{5}
			\min~&c^{\top}x\qquad\qquad &&\max ~ &&y^{\top}b\\
			&Ax = b && &&y^{\top}A\leq c^{\top}\\
			(\mathrm{P})\quad&x\geq  0 &&(\mathrm{D})\quad&&
		\end{alignedat}
	\]
	with \(y\) unrestricted. Then we have
	\[
		c^{\top}x\underset{?}{\geq} \underbrace{y^{\top}A}_{\leq c^{\top}}\underbrace{\vphantom{y^{\top}A}x}_{\geq 0} = y^{\top} b
	\]
	since \[
		y^{\top}Ax\leq c^{\top}x.
	\]
\end{answer}

\begin{intuition}
	For a minimization problem, we are just trying to find the lower bound of the \hyperref[def:objective-function]{objective function}'s value.
\end{intuition}

\begin{eg}
	Consider the following linear programming problem:
	\[
		\begin{aligned}
			\max~ & c^{\top}x+d^{\top}z            \\
			      & Ax\geq b                       \\
			      & Bx - Fz = g                    \\
			      & x\leq 0, z\text{ unrestricted}
		\end{aligned}
	\]
	Then the \hyperref[def:dual]{dual} is (with \hyperref[def:dual]{dual} variables \(y, w\))
	\[
		\begin{alignedat}{3}
			\min~ & y^{\top}b   &&+w^{\top}g            \\
			& y^{\top}A  &&+w^{\top}B  \leq c^{\top} \\
			& &&-w^{\top}F = d^{\top}    \\
			& y\leq &&0, w \text{ unrestricted},
		\end{alignedat}
	\]
	where we just look up the table for finding the \hyperref[def:dual]{dual}. Or, we can also find the \hyperref[def:dual]{dual} from
	\[
		\begin{split}
			&y^{\top} A + w^{\top} B\leq c^{\top}\\
			&(y^{\top} A+w^{\top} B)x\geq c^{\top} x
		\end{split},
	\]
	hence
	\[
		\begin{split}
			&\overbrace{y^{\top}}^{\leq 0}(Ax\geq b)\\
			+\ &w^{\top}(Bx - Fz = g)\\
			\cline{1-2}
			c^{\top}x + d^{\top}z\overset{\text{want}}{\leq}&\underbrace{y^{\top}Ax + w^{\top}Bx - w^{\top} Fz}_{\underbrace{(y^{\top} A + w^{\top} B)}_{\leq c^{\top}}\underbrace{\vphantom{y^{\top}A}x}_{\leq 0} \underbrace{- (w^{\top} F)z}_{=d^{\top}}} \overset{\text{want}}{\leq} y^{\top}b+w^{\top}g
		\end{split}
	\]
\end{eg}
\begin{remark}
	Think about what if all are equal sign? (both in constraints and variables, namely unrestricted)
\end{remark}

\section{Theorems of the Alternative}
In this section, we want to characterize when a \hyperref[def:general-linear-programming-problem]{linear program} has a \hyperref[def:feasible-solution]{feasible solution} by studying the \hyperref[def:dual]{duality}.

\subsection{Farkas Lemma}
Let's first study a motivating lemma called \hyperref[lma:Gauss]{Gauss' lemma}.

\begin{lemma}[Gauss' Lemma]\label{lma:Gauss}
	Exactly one of \((\mathrm{I})\) or \((\mathrm{II})\) has a solution:
	\[
		\begin{aligned}
			(\mathrm{I})\quad & Ax = b,
		\end{aligned}\quad
		\begin{aligned}
			                   & y^{\top}A\geq 0   \\
			(\mathrm{II})\quad & y^{\top}b\neq  0.
		\end{aligned}
	\]
\end{lemma}
\begin{proof}
	This just follows from the Gauss elimination. By doing the elimination, there are two cases.
	\begin{enumerate}[(a)]
		\item The system has no solution.
		\item There is a(some) solution(s).
	\end{enumerate}

	For second case, it's just \(Ax = b\) is solvable.  For the fist case, we see that after the elimination, we will have something like
	\[
		\begin{pmatrix}
			  &   &   &       &   &   &   \\
			  &   &   &       &   &   &   \\
			0 & 0 & 0 & \dots & 0 & 0 & 0 \\
			  &   &   &       &   &   &   \\
			  &   &   &       &   &   &   \\
		\end{pmatrix}
		\begin{pmatrix}
			\\
			\\
			a \\
			\\
			\\
		\end{pmatrix}
	\]
	where \(a\neq 0\), which just indicates this system is unsolvable.
\end{proof}

Now, let's see the \hyperref[lma:Farkas]{Farkas lemma}.

\begin{lemma}[Farkas Lemma]\label{lma:Farkas}
	For any data \(A\) and \(b\), then exactly one of \((\mathrm{I})\) or \((\mathrm{II})\) has a solution:
	\[
		\begin{aligned}
			                   & Ax = b   \\
			(\mathrm{I}) \quad & x\geq 0, \\
		\end{aligned}\quad
		\begin{aligned}
			                    & y^{\top}b > 0    \\
			(\mathrm{II}) \quad & y^{\top}A\leq 0.
		\end{aligned}
	\]
\end{lemma}

\begin{figure}[H]
	\centering
	\incfig{Farkas-lemma}
	\caption{Geometrically point of view with \(\mathbb{R}^m, m = 2\) }
	\label{fig:Farkas-lemma}
\end{figure}

\begin{intuition}
	We outline the idea about the proof.
	\begin{itemize}
		\item Step 1: \((\mathrm{I})\) and \((\mathrm{II})\) can't both have solutions for the same \(A, b\). Suppose \(\hat{x}\) solves \((\mathrm{I})\) and \(\hat{y}\) solves \((\mathrm{II})\). Then we have
		      \[
			      0\geq \underbrace{\hat{y}^{\top} A}_{\leq \vec{0}} \underbrace{\vphantom{\hat{y}^{\top}A} \hat{x}}_{\geq \vec{0}} = \hat{y}^{\top} b\ \conta
		      \]
		\item Step 2: Show that if \((\mathrm{I})\) has no solution, then \((\mathrm{II})\) has a solution.
	\end{itemize}
\end{intuition}